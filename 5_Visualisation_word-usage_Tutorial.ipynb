{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is part 5 of the 5 parts tutorial to show you how to plot word (verbs in our case) usage over time! \n",
    "#The code will plot the usage of the most frequent 3 verbs in the CCC titles showing how the usage differs across the years.\n",
    "#Our data-set is a list of talks and abstracts from the CCC conference https://gitlab.com/maxigas/cccongresstalks/\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "combinedFile = \"csvs/combined_csv.csv\"\n",
    "\n",
    "df = pd.read_csv(combinedFile, delimiter=',', header=0)\n",
    "print('Number of titles: {:,}\\n'.format(df.shape[0]))\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading titles (title is a column in the csv file as shown in the sample above)\n",
    "\n",
    "#loop through the titles and store them in a dictionary.\n",
    "\n",
    "title_dict = {}\n",
    "\n",
    "# classify that the article has recommends\n",
    "for i in range(len(df)):\n",
    "    if df[\"title\"][i] in title_dict.keys():\n",
    "        title_dict[df[\"title\"][i]] += 1\n",
    "    else:\n",
    "        title_dict.setdefault(df[\"title\"][i], 1)\n",
    "\n",
    "title_dict = [x for x in title_dict if str(x) != 'nan']#some talks may have no titles, just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning titles text keeping only letters\n",
    "import re\n",
    "title_text = \" \".join(x for x in title_dict)\n",
    "\n",
    "title_text = re.sub('[^a-zA-Z -\\']+', '', title_text)\n",
    "title_text = title_text.replace('>', ' ').replace('<', ' ')\n",
    "title_text = re.sub(' +', ' ', title_text)\n",
    "title_text = title_text.replace('hackz', 'hack').replace('securityz', 'security').replace('attackz','attacks').replace('Anfngerz','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using NLTK stop words removal process to remove english and german stop words and any word with less than 5 letters.\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "de_stop = set(nltk.corpus.stopwords.words('german'))\n",
    "\n",
    "def check_stop_lists(token):\n",
    "    if token in en_stop or token in de_stop:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_length(token):\n",
    "    if len(token) > 4:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the most common words in the CCC talk titles\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 200000 #sometimes if this number is smaller than the max length of your text you'll receive an error asking you to increase the max length\n",
    "doc = nlp(title_text)\n",
    "\n",
    "#remove stopwords, punctuations and words (verbs in our case) that are less than 5 letters long.\n",
    "\n",
    "verbs = [token.text for token in doc if check_stop_lists(token.text.lower()) == False and check_length(token.text) == True and token.is_punct != True and token.pos_ == \"VERB\"]\n",
    "\n",
    "#you can repeat the obove for nouns and most common words\n",
    "#nouns = [token.text for token in doc if check_stop_lists(token.text.lower()) == False and check_length(token.text) == True and token.is_punct != True and token.pos_ == \"NOUN\"]\n",
    "#words = [token.text for token in doc if check_stop_lists(token.text.lower()) == False and check_length(token.text) == True and token.is_punct != True]\n",
    "\n",
    "\n",
    "word_freq = Counter(verbs)\n",
    "common_verbs = word_freq.most_common(10)\n",
    "print(common_verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of all years in the CCC csvs (to help loop through years)\n",
    "years = df.year.unique()\n",
    "yearsList = []\n",
    "for y in years:\n",
    "    yearsList.append(str(y).replace('.0',''))#in some cases the years will end with a decimal e.g. 1990.0 this is due to difference between windows and linux/mac integer format, no harm in keeping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns frequency of a word over years (35 years in our case)\n",
    "def getFrequencies(word,yearsList):\n",
    "    yearsList.sort()\n",
    "    frequencies=[]\n",
    "    wordFreq = 0\n",
    "\n",
    "    for year in yearsList:\n",
    "        urlCSV = 'csvs/'+year+'.csv'\n",
    "        #print(year)\n",
    "        # load the data with pd.read_csv\n",
    "        data = pd.read_csv(urlCSV, delimiter='|',error_bad_lines=False)\n",
    "        #print(year, '  Number of titles: {:,}\\n'.format(data.shape[0]))\n",
    "        alltxt = data.title.str.lower()\n",
    "        \n",
    "        #data['abstract'].value_counts()\n",
    "\n",
    "        freq = alltxt.str.split(expand=True).stack().value_counts()\n",
    "\n",
    "        for name, val in freq.iteritems():\n",
    "            if name.lower()==word.lower():\n",
    "                wordFreq = val\n",
    "        #print(word, wordFreq)\n",
    "        frequencies.append(wordFreq)\n",
    "    \n",
    "    return frequencies   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a method to plot the most common words (verbs) and their frequencies over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotFrequencies(word,yearsList,frequencies):\n",
    "    yearsList.sort()\n",
    "    title_word = word+' Usage Over Years'\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(title_word, fontsize=10)\n",
    "    plt.xlabel('Years', fontsize=8)\n",
    "    plt.ylabel('Frequency', fontsize=8)\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,2)\n",
    "\n",
    "    plt.plot(yearsList, frequencies)\n",
    "    # You can specify a rotation for the tick labels in degrees or with keywords.\n",
    "    plt.xticks(yearsList, yearsList, rotation='vertical')\n",
    "\n",
    "    # Pad margins so that markers don't get clipped by the axes\n",
    "    plt.margins(0,0.20)\n",
    "    # Tweak spacing to prevent clipping of tick-labels\n",
    "    plt.subplots_adjust(bottom=0.30)\n",
    "    pltFileName = 'plots'+'/'+'word_usage'+'_'+word+'.pdf';\n",
    "    plt.savefig(pltFileName)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the verbs in the common_verbs array and create a plot for each word\n",
    "for key, value in common_verbs:\n",
    "    print(key)\n",
    "    plotFrequencies(key,yearsList,getFrequencies(key,yearsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
