{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial 3: Visualising with Word Clouds\n",
    "#author: Dr Mahmoud El-Haj (with help from the Internet) as part of the \"Visualise My Corpus Tutorial\" an event by Lanacaster University's UCREL and DSG Seminars\n",
    "#GitHub repository: https://github.com/drelhaj/NLP_ML_Visualization_Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We go a step forward by showing you how to create noun-clouds and verb-clouds using SpaCy.\n",
    "#Our data-set is a list of talks and abstracts from the CCC conference https://gitlab.com/maxigas/cccongresstalks/\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import helpers\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from imageio import imread\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#The following are options that will apear on the Word-Cloud plot later on.\n",
    "mpl.style.use('ggplot')\n",
    "infosize = 12\n",
    "limit = 10000\n",
    "title = 'Most frequent words'\n",
    "chartinfo = 'Author: Mahmoud El-Haj'\n",
    "footer = 'The {} most frequent words, excluding English stopwords.\\n{}'.format(limit, chartinfo)\n",
    "font = 'font/Ubuntu-B.ttf'\n",
    "fontcolor='#fafafa'\n",
    "bgcolor = '#000000'\n",
    "\n",
    "#loading English and German stop-words then combining the two sets in one\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')#you may turn this one off if you've already downloaded the wordnet   \n",
    "nltk.download('stopwords')#download the stopword lists from NLTK. Can be turned off if already downloaded\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "de_stop = set(nltk.corpus.stopwords.words('german'))\n",
    "\n",
    "\n",
    "both_stop_words = en_stop.union(de_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#Reading a the 2019 CCC talks, which is stored as a CSV file\n",
    "File2019_df = pd.read_csv(\"csvs/2019.csv\", delimiter='|', header=0)#notice the delimiter is not a comma, check your files first.\n",
    "print('Number of titles: {:,}\\n'.format(File2019_df.shape[0]))\n",
    "File2019_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading abstracts (abstract is a column in the csv file as shown in the sample above)\n",
    "\n",
    "#loop through the abstracts and store them in a dictionary.\n",
    "\n",
    "abstract_dict = {}\n",
    "\n",
    "# classify that the article has recommends\n",
    "for i in range(len(File2019_df)):\n",
    "    if File2019_df[\"abstract\"][i] in abstract_dict.keys():\n",
    "        abstract_dict[File2019_df[\"abstract\"][i]] += 1\n",
    "    else:\n",
    "        abstract_dict.setdefault(File2019_df[\"abstract\"][i], 1)\n",
    "\n",
    "abstract_dict = [x for x in abstract_dict if str(x) != 'nan']#some talks have no abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a method for a grey colour wordcloud\n",
    "def grey_color(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    return 'hsl(0, 0%%, %d%%)' % random.randint(50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the abstracts most frequent words as a wordcloud!\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "mask = np.array(Image.open(r'img\\1.jpg'))\n",
    "plt.imshow(mask)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#abstracts text\n",
    "import re\n",
    "abstract_text = \" \".join(x for x in abstract_dict)\n",
    "\n",
    "abstract_text = re.sub('[^a-zA-Z -\\']+', '', abstract_text)\n",
    "abstract_text = abstract_text.replace('>', ' ').replace('<', ' ')\n",
    "abstract_text = re.sub(' +', ' ', abstract_text)\n",
    "\n",
    "#The mask image will guide the word-cloud to take the shape of that image.\n",
    "#In our case it's a silhouette of a hacker (goes along with the CCC conference)\n",
    "#notice the word-cloud will contain English and German stop words as we didn't handle them\n",
    "wordcloud = WordCloud(\n",
    "    max_words=limit,\n",
    "    stopwords=both_stop_words,\n",
    "    mask=imread('img/1.jpg'),\n",
    "    background_color=bgcolor,\n",
    "    font_path=font\n",
    ").generate(abstract_text)\n",
    "\n",
    "#set width and height\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14)\n",
    "fig.set_figheight(18)\n",
    "\n",
    "#plot!\n",
    "plt.imshow(wordcloud.recolor(color_func=grey_color, random_state=3))\n",
    "plt.title(title, color=fontcolor, size=30, y=1.01)\n",
    "plt.annotate(footer, xy=(0, -.025), xycoords='axes fraction', fontsize=infosize, color=fontcolor)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above but the word-cloud follows (masks) the colours in the image itself rather than the grey colour we chose earlier\n",
    "#notice the word-cloud will contain English and German stop words as we didn't handle them\n",
    "#setting mask image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "mask = np.array(Image.open(r'img\\4.jpg'))\n",
    "plt.imshow(mask)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size, change the maximum number of word and lighten the background:\n",
    "from wordcloud import ImageColorGenerator\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    max_words=limit,\n",
    "    stopwords=both_stop_words,\n",
    "    width=2000, height=1000,\n",
    "    contour_color=\"black\", \n",
    "    relative_scaling = 0,\n",
    "    mask=mask,\n",
    "    background_color=\"white\",\n",
    "    font_path=font\n",
    ").generate(abstract_text)\n",
    "\n",
    "#creating wordcloud\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we go a step further than just words frequency \n",
    "#instead we choose a cleaner version of the text, no stop words, no words less than 5 letters and only NOUNS (see other options below)\n",
    "\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(abstract_text)\n",
    "#remove stopwords and punctuations\n",
    "\n",
    "nouns = [token.text for token in doc if token.is_stop != True and len(token)>4 and token.is_punct != True and token.pos_ == \"NOUN\"] #creates a noun-cloud\n",
    "#words = [token.text for token in doc if token.is_stop != True and token.is_punct != True] #this is based on words frquency\n",
    "#verbs = [token.text for token in doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"VERB\"] #this selects verbs only (verbs-cloud)\n",
    "\n",
    "\n",
    "# 500 most common noun tokens (you can change the number)\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(500)\n",
    "print (common_nouns[0:10])\n",
    "\n",
    "#uncomment the examples below if you'd like other text rather than nouns\n",
    "#word_freq = Counter(words)\n",
    "#common_words = word_freq.most_common(20)\n",
    "#print (common_words)\n",
    "\n",
    "# five most common verbs tokens\n",
    "#verb_freq = Counter(verbs)\n",
    "#common_verbs = verb_freq.most_common(20)\n",
    "#print (common_verbs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all nouncs as one single string to pass it to the word-cloud plotter\n",
    "allNouns= ( x[0] for x in common_nouns )\n",
    "allNounsText = ' '.join(str(e) for e in allNouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------\n",
    "#setting mask image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "mask = np.array(Image.open(r'img\\4.jpg'))\n",
    "plt.imshow(mask)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size, change the maximum number of word and lighten the background:\n",
    "from wordcloud import ImageColorGenerator\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "#creating wordcloud\n",
    "wordcloud = WordCloud(\n",
    "    max_words=limit,\n",
    "    stopwords=both_stop_words,\n",
    "    width=2000, height=1000,\n",
    "    contour_color=\"black\", \n",
    "    relative_scaling = 0,\n",
    "    mask=mask,\n",
    "    background_color=\"white\",\n",
    "    font_path=font\n",
    ").generate(abstract_text)\n",
    "\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[20,15])\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
